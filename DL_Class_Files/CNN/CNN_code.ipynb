{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","authorship_tag":"ABX9TyODk4zVm++ZCjE2vqI2iNcI"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"gvyjdGrZsv7K"},"source":["[statinfer.com](https://statinfer.com/)"]},{"cell_type":"markdown","metadata":{"id":"GSm3YuKTTX19"},"source":["# Packages"]},{"cell_type":"code","metadata":{"id":"s0eQEyzoqB8S"},"source":["#Importing dependencies\n","import tensorflow\n","import tensorflow.keras as keras\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D,Dropout\n","from tensorflow.keras.preprocessing import image\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import urllib.request\n","from tensorflow.keras import datasets\n","%matplotlib inline\n","from PIL import Image\n","from PIL import ImageFont\n","from PIL import ImageDraw"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_uk-GVhc7vZT"},"source":["# Filter"]},{"cell_type":"code","metadata":{"id":"8D9cbcpxtAt1"},"source":["#read cat image\n","urllib.request.urlretrieve(\"https://raw.githubusercontent.com/venkatareddykonasani/Datasets/master/cat/cat.jpeg\", \"cat.jpeg\")\n","x=plt.imread('cat.jpeg')\n","plt.imshow(x)\n","print(x.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rz-Qw_bouWGC"},"source":["model=Sequential()\n","model.add(Conv2D(filters=1, kernel_size=(5,5), input_shape=x.shape, kernel_initializer='random_uniform'))\n","model.summary()\n","\n","#Draw CNN Image\n","batch_value=np.expand_dims(x,axis=0)\n","batch_value=model.predict(batch_value)\n","final_image=np.squeeze(batch_value,axis=0)\n","flat_image=final_image.flatten()\n","pixels = np.matrix(flat_image)\n","pixels=pixels.reshape(batch_value.shape[1],batch_value.shape[2])\n","plt.title(\"Image After Applying Filter\")\n","plt.imshow(pixels)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0occNga9qgZo"},"source":["# Pooling"]},{"cell_type":"markdown","metadata":{"id":"mHxpCLd4qgZp"},"source":["Exersize-1: Apply 3X3 convolution filer and then apply 2X2 max pooling matrix"]},{"cell_type":"code","metadata":{"id":"DMApye_IqgZq"},"source":["def Visualize(model, cat):\n","    '''prints the cat as a 2d array'''\n","    cat_batch = np.expand_dims(cat,axis=0)\n","    conv_cat2 = model.predict(cat_batch)\n","    conv_cat2 = np.squeeze(conv_cat2, axis=0)\n","    conv_cat2 = conv_cat2.reshape(conv_cat2.shape[:2])\n","    print(\"Shape after pooling \",  conv_cat2.shape)\n","    plt.imshow(conv_cat2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DFy0DX0bqgZu"},"source":["model=Sequential()\n","model.add(Conv2D(1,\n","                 (3,3),\n","                 input_shape=x.shape,\n","                ))\n","model.add(MaxPooling2D(pool_size=(2,2)))\n","\n","#We visualize change the filter size to see the difference\n","Visualize(model, x)\n","print(\"Original Image Shape\",  x.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WcSw5lr4IJkf"},"source":["# CNN Example"]},{"cell_type":"markdown","metadata":{"id":"tz9e_5pnJ0as"},"source":["## Import Data"]},{"cell_type":"code","metadata":{"id":"wcWJFJuyHUE-"},"source":["import tensorflow as tf\n","from tensorflow.keras import datasets, layers, models\n","import matplotlib.pyplot as plt\n","\n","(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n","\n","# Normalize pixel values to be between 0 and 1\n","train_images, test_images = train_images / 255.0, test_images / 255.0"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Un3q08TZJ2pj"},"source":["## Look at the data"]},{"cell_type":"code","metadata":{"id":"1gCPvbBxINfH"},"source":["class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n","               'dog', 'frog', 'horse', 'ship', 'truck']\n","\n","plt.figure(figsize=(10,10))\n","for i in range(25):\n","    plt.subplot(5,5,i+1)\n","    plt.xticks([])\n","    plt.yticks([])\n","    plt.grid(False)\n","    plt.imshow(train_images[i], cmap=plt.cm.binary)\n","    # The CIFAR labels happen to be arrays,\n","    # which is why you need the extra index\n","    plt.xlabel(class_names[train_labels[i][0]])\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CHFdI8KmJ5a-"},"source":["## Configure CNN model"]},{"cell_type":"code","metadata":{"id":"JE_gK6szIUnK"},"source":["model = models.Sequential()\n","\n","model.add(layers.Conv2D(16, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n","#For Detecting low level features\n","model.add(layers.MaxPooling2D((2, 2)))\n","\n","model.add(layers.Conv2D(32, (3, 3), activation='relu'))\n","#For Detecting Mid level features - Higher than previous conv layer\n","model.add(layers.MaxPooling2D((2, 2)))\n","\n","model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n","#High level features - Higher than previous conv layer\n","model.add(layers.MaxPooling2D((2, 2)))\n","\n","model.add(layers.Flatten())\n","model.add(layers.Dense(64, activation='relu'))\n","model.add(layers.Dense(10))\n","model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EqK8jpvnJ8H2"},"source":["## Compile and fit the model"]},{"cell_type":"code","metadata":{"id":"7or1RprnI0Ld"},"source":["model.compile(optimizer='adam',\n","              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","              metrics=['accuracy'])\n","\n","model.fit(train_images, train_labels, epochs=2, batch_size=64,validation_data=(test_images, test_labels))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-2NqcB9TPMlW"},"source":["## Save and load the model"]},{"cell_type":"code","metadata":{"id":"2v3lBlQQI1-h"},"source":["model.save_weights('cifar10_model_v1.h5')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RQmuUWqtI32M"},"source":["model.load_weights('cifar10_model_v1.h5')\n","model.fit(train_images, train_labels, epochs=2, batch_size=64,\n","                    validation_data=(test_images, test_labels))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gSRVMEsiPQOk"},"source":["## Importing the saved model"]},{"cell_type":"code","metadata":{"id":"soTKbiUfJtt2"},"source":["urllib.request.urlretrieve(\"https://raw.githubusercontent.com/venkatareddykonasani/Datasets/master/CNN_Model/cifar10_model_v2.h5\", \"cifar10_model_v2.h5\")\n","model.load_weights(\"cifar10_model_v2.h5\")\n","model.fit(train_images, train_labels, epochs=2, batch_size=64,\n","                    validation_data=(test_images, test_labels))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"429hzb_XPli9"},"source":["# Object Detection using Resnet"]},{"cell_type":"code","metadata":{"id":"yENWq213LRTp"},"source":["from tensorflow.keras.applications.resnet50 import ResNet50\n","from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gFoJowWsP-Wr"},"source":["model = ResNet50(weights='imagenet')\n","#This code will docwnload the pretrained weights\n","#You can manually copy the file to cache folders\n","#The temp folder location"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1SkDAxC5QPRf"},"source":["## Load and Predict the objects in the image"]},{"cell_type":"code","metadata":{"id":"JrPlrD8iQLkH"},"source":["image_name=\"3.jpg\" # try 2.jpg and 3.jpg\n","urllib.request.urlretrieve(\"https://raw.githubusercontent.com/venkatareddykonasani/Datasets/master/Sample_images/\"+image_name, image_name)\n","img = image.load_img(image_name, target_size=(224, 224))\n","x = image.img_to_array(img)\n","x = np.expand_dims(x, axis=0)\n","x = preprocess_input(x)\n","\n","### Prediction\n","preds = model.predict(x)\n","# decode the results into a list of tuples (class, description, probability)\n","# (one such list for each sample in the batch)\n","prediction = '\\n'.join(map(str, decode_predictions(preds, top=3)[0]))\n","print('\\n',prediction,'\\n')\n","draw = ImageDraw.Draw(img)\n","draw.text((10, 10),prediction,(250,0,0))\n","img.save('sample-out.jpg')\n","plt.imshow(img)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"H7qMn80PWuW7"},"source":["# Malaria Detection - Case Study"]},{"cell_type":"code","metadata":{"id":"bf9ZGqu_yU8r"},"source":["#Let us keep all the libraries ready\n","import tensorflow.keras as keras\n","from tensorflow.keras.models import Model, Sequential\n","from tensorflow.keras.layers import Dense, Dropout, Flatten, Input, AveragePooling2D,  Activation\n","from tensorflow.keras.layers import Reshape, Input, Lambda\n","from tensorflow.keras.layers import Conv2D, Convolution2D, MaxPooling2D, BatchNormalization\n","from tensorflow.keras.layers import Concatenate, GlobalAveragePooling2D\n","from tensorflow.keras.optimizers import Adam, SGD\n","from tensorflow.keras import regularizers, initializers\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","import pandas as pd\n","import numpy as np\n","\n","from sklearn.metrics import confusion_matrix\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","from PIL import Image\n","from matplotlib.pyplot import imshow, imsave\n","import imageio\n","import random\n","import urllib.request\n","\n","from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7TGkoqKawks9"},"source":["## Get the data"]},{"cell_type":"code","metadata":{"id":"C-LO616Lv_4k"},"source":["auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)\n","downloaded = drive.CreateFile({'id':\"119UU7nc57Ng4L8-69hnXiiIcmOU8nzJT\"})\n","downloaded.GetContentFile('cell_images.zip')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aa0pyB71R7Fb"},"source":["!unzip -qq 'cell_images.zip'\n","!ls ./cell_images"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ra2l7d0VLARD"},"source":["## Sample Images"]},{"cell_type":"markdown","metadata":{"id":"PN85q1teNhkV"},"source":["### Infected Cells - sample images"]},{"cell_type":"code","metadata":{"id":"w-SvKLT5LCEj"},"source":["fig, ax = plt.subplots(2,2)\n","location='./cell_images/Parasitized/'\n","\n","img=imageio.imread(location+\"C46P7ThinF_IMG_20151130_210743_cell_154.png\")\n","print(img.shape)\n","ax[0,0].imshow(img)\n","\n","img=imageio.imread(location+\"C39P4thinF_original_IMG_20150622_111942_cell_7.png\")\n","print(img.shape)\n","ax[0,1].imshow(img)\n","\n","img=imageio.imread(location+\"C189P150ThinF_IMG_20151203_141615_cell_93.png\")\n","print(img.shape)\n","ax[1,0].imshow(img)\n","\n","img=imageio.imread(location+\"C143P104ThinF_IMG_20151005_225413_cell_181.png\")\n","print(img.shape)\n","ax[1,1].imshow(img)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Wi4hJjAZNksl"},"source":["### Un-infected Cell - Sample images"]},{"cell_type":"code","metadata":{"id":"4QfuLJkHLCJD"},"source":["fig, ax = plt.subplots(2,2)\n","location='./cell_images/Uninfected/'\n","\n","img=imageio.imread(location+\"C2NThinF_IMG_20150604_114631_cell_38.png\")\n","print(img.shape)\n","ax[0,0].imshow(img)\n","\n","img=imageio.imread(location+\"C189P150ThinF_IMG_20151203_141455_cell_51.png\")\n","print(img.shape)\n","ax[0,1].imshow(img)\n","\n","img=imageio.imread(location+\"C5NThinF_IMG_20150609_122108_cell_117.png\")\n","print(img.shape)\n","ax[1,0].imshow(img)\n","\n","img=imageio.imread(location+\"C149P110ThinF_IMG_20151115_114910_cell_237.png\")\n","print(img.shape)\n","ax[1,1].imshow(img)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mauU7oWBK8w0"},"source":["## Train and Test Data Generation"]},{"cell_type":"code","metadata":{"id":"hcS36EYXYUfb"},"source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","########################\n","# Data generator : Any preprocessing options/steps can be  defined here\n","########################\n","datagen = ImageDataGenerator(rescale = 1./255,  # scaling the images matrix(standard preprocessing step)\n","                             validation_split=0.2) # set validation split\n","width = 128\n","height = 128"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JqDHAAEhS7Z_"},"source":["trainDatagen = datagen.flow_from_directory(directory='/content/cell_images',\n","                                           target_size=(width,height),  # resizing the input images to a specific size\n","                                           class_mode = 'binary', #binary or categorical\n","                                           batch_size = 256,\n","                                           subset='training')  # set as training data"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nYcf9j4pX3oQ"},"source":["valDatagen = datagen.flow_from_directory(directory='/content/cell_images',\n","                                           target_size=(width,height),\n","                                           class_mode = 'binary',\n","                                           batch_size = 256,\n","                                           subset='validation')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tReFieZHZEt_"},"source":["## Model Building"]},{"cell_type":"code","metadata":{"id":"moFSkeNmRyq5"},"source":["model = Sequential()\n","model.add(Conv2D(8,(3,3),activation='relu',input_shape=(width,height,3)))\n","model.add(MaxPooling2D(2,2))\n","model.add(Dropout(0.2))\n","\n","model.add(Conv2D(16,(3,3),activation='relu'))\n","model.add(MaxPooling2D(2,2))\n","model.add(Dropout(0.3))\n","\n","model.add(Conv2D(32,(3,3),activation='relu'))\n","model.add(MaxPooling2D(2,2))\n","model.add(Dropout(0.3))\n","\n","model.add(Flatten())\n","model.add(Dense(64,activation='relu'))\n","model.add(Dropout(0.5))\n","\n","model.add(Dense(1,activation='sigmoid'))\n","model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cA_J81ZLZPvr"},"source":["model.compile(optimizer ='adam',  loss =keras.losses.binary_crossentropy, metrics = ['accuracy'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"51PVCnlgZwMN"},"source":["model.fit(\n","        trainDatagen,\n","        steps_per_epoch = len(trainDatagen), #total number of batches in one train epoch(train observation/batch size; also called iterations per epoch)\n","        epochs=10,\n","        validation_data =  valDatagen,\n","        validation_steps = len(valDatagen), #total number of batches in validation(validation observation/batch size)\n","        verbose=1\n","        )"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"48iOp-IRa48J"},"source":["## Save and Re-train the model"]},{"cell_type":"code","metadata":{"id":"XU6q4Px_adUi"},"source":["model.save_weights('model_10epochs.h5')\n","\n","model.fit(\n","        trainDatagen,\n","        steps_per_epoch = len(trainDatagen), #total number of batches in one train epoch(train observation/batch size; also called iterations per epoch)\n","        epochs=1,\n","        validation_data =  valDatagen,\n","        validation_steps = len(valDatagen), #total number of batches in validation(validation observation/batch size)\n","        verbose=1\n","        )\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pUz4Vjn5PaGc"},"source":["urllib.request.urlretrieve(\"https://raw.githubusercontent.com/venkatareddykonasani/Datasets/master/malaria_detection_models/malaria_detection_30epochs.h5\", \"malaria_detection_30epochs.h5\")\n","model.load_weights(\"malaria_detection_30epochs.h5\")\n","\n","model.fit(\n","        trainDatagen,\n","        steps_per_epoch = len(trainDatagen), #total number of batches in one train epoch(train observation/batch size; also called iterations per epoch)\n","        epochs=1,\n","        validation_data =  valDatagen,\n","        validation_steps = len(valDatagen), #total number of batches in validation(validation observation/batch size)\n","        verbose=1\n","        )"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PoSMaZ-naL6f"},"source":["## Prediction on new data"]},{"cell_type":"code","metadata":{"id":"D0DU0a1maK26"},"source":["urllib.request.urlretrieve(\"https://raw.githubusercontent.com/venkatareddykonasani/Datasets/master/malaria_detection_models/cell_images_extra.zip\", \"cell_images_extra.zip\")\n","!unzip -qq 'cell_images_extra.zip'\n","\n","image_path = '/content/cell_images_extra'\n","model.load_weights(\"malaria_detection_30epochs.h5\")\n","\n","test_datagen = ImageDataGenerator(rescale=1./255)\n","test_generator = test_datagen.flow_from_directory(\n","        image_path,\n","        target_size=(width, height),\n","        batch_size=1,\n","        class_mode='binary',\n","        shuffle=False)\n","\n","len(test_generator)\n","\n","# Predict from generator (returns probabilities)\n","pred=model.predict_generator(test_generator, steps=len(test_generator), verbose=1)\n","\n","# Get classes by np.round\n","cl = np.round(pred)\n","# Get filenames (set shuffle=false in generator is important)\n","filenames=test_generator.filenames\n","\n","# Data frame\n","results=pd.DataFrame({\"file\":filenames,\"pr\":pred[:,0], \"class\":cl[:,0]})\n","print(results)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DbBDlByWa42t"},"source":["%matplotlib inline\n","location='/content/cell_images_extra/'\n","\n","for i in range(0,6):\n","  plt.figure()\n","  plt.title([\"Prediction class\",results.iloc[i,2]])\n","  x=plt.imread(location+results.iloc[i,0])\n","  plt.imshow(x)\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dBn7joVJBy3-"},"source":[],"execution_count":null,"outputs":[]}]}